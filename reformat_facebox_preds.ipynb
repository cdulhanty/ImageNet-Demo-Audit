{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'inference/ILSVRC2012_training_dets.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {}\n",
    "dataset_dict['n_faces'] = 0\n",
    "dataset_dict['synsets'] = {}\n",
    "\n",
    "lines = []\n",
    "\n",
    "with open(PATH) as f:\n",
    "    \n",
    "    for i, l in enumerate(f):\n",
    "        lines.append(l)\n",
    "    n_lines = i + 1\n",
    "    \n",
    "    j = 0\n",
    "    while j < n_lines:\n",
    "    \n",
    "        if '.JPEG' in lines[j]:\n",
    "            image_dict = {}\n",
    "            image_dict['n_faces'] = 0\n",
    "            image_dict['faces'] = []\n",
    "            \n",
    "            synset = lines[j].split('_')[0]\n",
    "            \n",
    "            if synset not in dataset_dict['synsets']:\n",
    "              dataset_dict['synsets'][synset] = {}\n",
    "              dataset_dict['synsets'][synset]['n_faces'] = 0\n",
    "              dataset_dict['synsets'][synset]['images'] = {}\n",
    "                \n",
    "        if is_float(lines[j+1]):\n",
    "            \n",
    "            n_detections = int(float(lines[j+1]))\n",
    "            \n",
    "            for k in range(n_detections):\n",
    "                \n",
    "                detection_list = lines[j+2+k].split()\n",
    "                detection_dict = {}\n",
    "                \n",
    "                detection_dict['xmin'] = float(detection_list[0])\n",
    "                detection_dict['ymin'] = float(detection_list[1])\n",
    "                detection_dict['w'] = float(detection_list[2])\n",
    "                detection_dict['h'] = float(detection_list[3])\n",
    "                detection_dict['score'] = float(detection_list[4])\n",
    "                \n",
    "                image_dict['faces'].append(detection_dict)\n",
    "                image_dict['n_faces'] += 1\n",
    "                \n",
    "            dataset_dict['synsets'][synset]['n_faces'] += image_dict['n_faces']\n",
    "            dataset_dict['synsets'][synset]['images'][lines[j].strip()] = image_dict\n",
    "            dataset_dict['n_faces'] += image_dict['n_faces']\n",
    "            \n",
    "            j += n_detections + 2\n",
    "\n",
    "with open('inference/ILSVRC2012_training_dets.json', 'w') as f:\n",
    "    json.dump(dataset_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'xmin': 111.207, u'h': 32.87, u'ymin': 26.266, u'score': 0.9838662744, u'w': 25.732}\n"
     ]
    }
   ],
   "source": [
    "# example entry\n",
    "for synset in sorted(new_dict['synsets'].keys()):\n",
    "    for image in sorted(new_dict['synsets'][synset]['images'].keys()):\n",
    "        for face in new_dict['synsets'][synset]['images'][image]['faces']:\n",
    "            if face['score'] > 0.9:\n",
    "                print(face)\n",
    "                break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inference/ILSVRC2012_training_dets.json') as f:\n",
    "    new_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 817633)\n",
      "(0.2, 427656)\n",
      "(0.3, 326076)\n",
      "(0.4, 273268)\n",
      "(0.5, 237199)\n",
      "(0.6, 209540)\n",
      "(0.7, 185352)\n",
      "(0.8, 161285)\n",
      "(0.9, 132201)\n"
     ]
    }
   ],
   "source": [
    "for thresh in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    n_valid_faces = 0\n",
    "    for synset in sorted(new_dict['synsets'].keys()):\n",
    "\n",
    "        for image in sorted(new_dict['synsets'][synset]['images'].keys()):\n",
    "\n",
    "            for face in new_dict['synsets'][synset]['images'][image]['faces']:\n",
    "\n",
    "                if face['score'] > thresh:\n",
    "                    n_valid_faces += 1\n",
    "    print(thresh, n_valid_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
